{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c436b862-3c62-4ecb-ae8d-73ede0b1c637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import current_timestamp, lit\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b40204b-ec4a-4e56-9872-ed57839dd6ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_silver_path=\"/Volumes/customer_360/customer_360_silver/silver_customer_volume\"\n",
    "gold_path=\"/Volumes/customer_360/customer_360_gold/gold_customer_dim_volume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bd405e7-ab0c-43d9-9b31-e4240abb341b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"read silver data\").getOrCreate()\n",
    "df=spark.read\\\n",
    "    .format(\"delta\")\\\n",
    "    .load(\"/Volumes/customer_360/customer_360_silver/silver_customer_volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2247e8e0-e0fa-424c-82fb-74ace138e3ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if DeltaTable.isDeltaTable(spark, gold_path):\n",
    "    bronze_table = DeltaTable.forPath(spark, gold_path)\n",
    "    # Get max data_arrival_timestamp\n",
    "    max_ts_row = bronze_table.toDF().select(max(\"data_arrival_timestamp\")).collect()[0]\n",
    "    max_ts = max_ts_row[0]  # None if table is empty\n",
    "    if max_ts is None:\n",
    "        print(\"e table is empty. Will load all records.\")\n",
    "else:\n",
    "    print(\" table not found. Will load all records.\")\n",
    "    max_ts = None  # first load\n",
    "\n",
    "# Filter source for incremental load\n",
    "if max_ts:\n",
    "    df = df.filter(col(\"data_arrival_timestamp\") > max_ts)\n",
    "else:\n",
    "    df = df # first load, take all records\n",
    "\n",
    "print(f\"Number of records to load: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0ff0e0c-98de-44c9-bc19-66bd9f14f5b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 1: Add derived and tracking columns ---\n",
    "df = df.withColumn(\n",
    "    \"age_category\",\n",
    "    when(col(\"age\") < 20, \"Teenager\")\n",
    "    .when(col(\"age\") < 60, \"Adult\")\n",
    "    .otherwise(\"Senior Citizen\")\n",
    ").withColumn(\"start_date\", current_timestamp()) \\\n",
    " .withColumn(\"end_date\", lit(None).cast(TimestampType())) \\\n",
    " .withColumn(\"is_active\", lit(True))\n",
    "\n",
    "df_written = None\n",
    "\n",
    "# --- Step 2: Check if Delta table exists ---\n",
    "if DeltaTable.isDeltaTable(spark, gold_path):\n",
    "    print(\"âœ… Target table exists. Applying SCD Type 2 logic...\")\n",
    "\n",
    "    delta_table = DeltaTable.forPath(spark, gold_path)\n",
    "    df_existing = delta_table.toDF()\n",
    "    df_active_existing = df_existing.filter(col(\"is_active\") == True)\n",
    "\n",
    "    # Step 3: Detect changed customers\n",
    "    changes_df = df.alias(\"src\").join(\n",
    "        df_active_existing.alias(\"tgt\"),\n",
    "        on=col(\"src.customer_id\") == col(\"tgt.customer_id\"),\n",
    "        how=\"inner\"\n",
    "    ).filter(\n",
    "        (col(\"src.customer_name\") != col(\"tgt.customer_name\")) |\n",
    "        (col(\"src.segment\") != col(\"tgt.segment\")) |\n",
    "        (col(\"src.age\") != col(\"tgt.age\")) |\n",
    "        (col(\"src.country\") != col(\"tgt.country\")) |\n",
    "        (col(\"src.city\") != col(\"tgt.city\")) |\n",
    "        (col(\"src.state\") != col(\"tgt.state\")) |\n",
    "        (col(\"src.postal_code\") != col(\"tgt.postal_code\")) |\n",
    "        (col(\"src.region\") != col(\"tgt.region\"))\n",
    "    ).select(\"src.customer_id\").distinct()\n",
    "\n",
    "    # Step 4: Detect new customers\n",
    "    df_new_customers = df.alias(\"src\").join(\n",
    "        df_active_existing.alias(\"tgt\"),\n",
    "        on=col(\"src.customer_id\") == col(\"tgt.customer_id\"),\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "\n",
    "    # Step 5: Update changed customers\n",
    "    if changes_df.count() > 0:\n",
    "        print(\"ðŸ” Found changed records â€” applying SCD Type 2 updates...\")\n",
    "        changed_ids = [r[\"customer_id\"] for r in changes_df.collect()]\n",
    "\n",
    "        delta_table.update(\n",
    "            condition=col(\"customer_id\").isin(changed_ids) & (col(\"is_active\") == True),\n",
    "            set={\n",
    "                \"is_active\": lit(False),\n",
    "                \"end_date\": current_timestamp()\n",
    "            }\n",
    "        )\n",
    "\n",
    "        df_changed_customers = df.join(changes_df, on=\"customer_id\", how=\"inner\")\n",
    "    else:\n",
    "        df_changed_customers = spark.createDataFrame([], df.schema)\n",
    "\n",
    "    # Step 6: Combine new + changed records\n",
    "    df_to_insert = df_new_customers.unionByName(df_changed_customers)\n",
    "\n",
    "    # Step 7: Write if there are updates\n",
    "    if df_to_insert.count() > 0:\n",
    "        print(f\"ðŸ“¥ Appending {df_to_insert.count()} new/changed records...\")\n",
    "        df_written = spark.createDataFrame(df_to_insert.collect(), schema=df_to_insert.schema)\n",
    "        df_to_insert.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .option(\"mergeSchema\", \"true\") \\\n",
    "            .partitionBy(\"region\") \\\n",
    "            .save(gold_path)\n",
    "        print(\"âœ… SCD Type 2 update completed successfully.\")\n",
    "\n",
    "    else:\n",
    "        print(\"â„¹ï¸ No new or changed records. Nothing to insert.\")\n",
    "        df_written = spark.createDataFrame([], df.schema)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"ðŸš€ Creating new Delta table (first load)...\")\n",
    "    df_written = spark.createDataFrame(df.collect(), schema=df.schema)\n",
    "    df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .partitionBy(\"region\") \\\n",
    "        .save(gold_path)\n",
    "    print(\"âœ… New Delta table created.\")\n",
    "\n",
    "\n",
    "# df_written is for audit purpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b480a45c-38cc-423c-bb0e-2d5abee7db09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_written.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "498a9e7d-c3bc-4a19-b209-9f0e70d4a00f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Count records\n",
    "records_count = df_written.count()\n",
    "\n",
    "if records_count==0:\n",
    "    msg=\" (Source Empty)\"\n",
    "else:\n",
    "    msg=\"\"\n",
    "\n",
    "# max timestamp (only if rows exist)\n",
    "max_data_ts_row = (\n",
    "    df_written.select(max(\"data_arrival_timestamp\")).collect()[0][0]\n",
    "    if records_count > 0\n",
    "    else None\n",
    ")\n",
    "\n",
    "# Use Python datetime for load_time\n",
    "load_time = datetime.now()\n",
    "\n",
    "# Define schema explicitly\n",
    "schema = StructType([\n",
    "    StructField(\"layer\", StringType(), True),\n",
    "    StructField(\"table_name\", StringType(), True),\n",
    "    StructField(\"load_time\", TimestampType(), True),\n",
    "    StructField(\"records_loaded\", LongType(), True),\n",
    "    StructField(\"max_data_timestamp\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# Prepare audit data (even if 0 rows)\n",
    "data = [(\"gold\", f\"gold_customer{msg}\", load_time, records_count, max_data_ts_row)]\n",
    "\n",
    "# Create DataFrame\n",
    "df_audit = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Append to audit table\n",
    "df_audit.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save(\"/Volumes/customer_360/audit/audit_volume/etl_audit\")\n",
    "\n",
    "print(f\"Audit log updated successfully. Records loaded: {records_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa1bb6b4-ab1b-4da8-b0ef-6712ac53a291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/customer_360/customer_360_gold/gold_customer_dim_volume`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8ef840a-caa3-4211-a267-0d8a8dacba01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TRUNCATE TABLE delta.`/Volumes/customer_360/customer_360_gold/gold_customer_dim_volume`\n",
    "-- UPDATE delta.`/Volumes/customer_360/customer_360_gold/gold_customer_dim_volume`\n",
    "-- SET postal_code = 9999\n",
    "-- WHERE customer_id = 'CUST0002';\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cab986df-8934-43d5-81b0-414d7aab5c1f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"load_time\":261},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762783002654}",
       "filterBlob": "{\"version\":1,\"filterGroups\":[{\"enabled\":true,\"filterGroupId\":\"fg_4633d200\",\"op\":\"OR\",\"filters\":[{\"filterId\":\"f_43893d5a\",\"enabled\":true,\"columnId\":\"load_time\",\"dataType\":\"datetime\",\"filterType\":\"oneof\"}],\"local\":false,\"updatedAt\":1762783236383}],\"syncTimestamp\":1762783236383}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/customer_360/audit/audit_volume/etl_audit`"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7001818358103981,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver to gold customer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
